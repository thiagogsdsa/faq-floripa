from sentence_transformers import SentenceTransformer
from preprocessor import Preprocessor
import faiss
import numpy as np


class FAQEmbedder:
    def __init__(self, faq_list, language='pt', model_name='paraphrase-multilingual-MiniLM-L12-v2'):
        self.language = language
        self.preprocessor = Preprocessor(language)
        self.model = SentenceTransformer(model_name)
        self.faq_list = faq_list

        # Clean questions before encoding
        self.texts = [self.preprocessor.clean(f[f"question_{language}"]) for f in faq_list]
        self.answers = [f[f"answer_{language}"] for f in faq_list]
        self.ids = [f["id"] for f in faq_list]

        self.index = self._build_index()

    def _build_index(self):
        embeddings = self.model.encode(self.texts, convert_to_numpy=True)
        faiss.normalize_L2(embeddings)
        index = faiss.IndexFlatIP(embeddings.shape[1])
        index.add(embeddings)
        return index






#class FAQEmbedder:
#    def __init__(self, faq_list, language='pt', model_name='paraphrase-multilingual-MiniLM-L12-v2'):
#        self.language = language
#        self.preprocessor = Preprocessor(language)
#        self.model = SentenceTransformer(model_name)
#        self.faq_list = faq_list
#
#        # Clean questions before encoding
#        self.texts = [self.preprocessor.clean(f[f"question_{language}"]) for f in faq_list]
#        self.answers = [f[f"answer_{language}"] for f in faq_list]
#        self.ids = [f["id"] for f in faq_list]
#
#        self.index = self._build_index()
#
#    def _build_index(self):
#        embeddings = self.model.encode(self.texts, convert_to_numpy=True)
#        faiss.normalize_L2(embeddings)
#        index = faiss.IndexFlatIP(embeddings.shape[1])
#        index.add(embeddings)
#        return index
#


















#class MultilingualFAQRetrieverEmbedder:
#    def __init__(self, faq_list, language='pt', model_name='paraphrase-multilingual-MiniLM-L12-v2'):
#        self.language = language  # 'pt' ou 'en'
#        self.faq_list = faq_list
#        self.model = SentenceTransformer(model_name)
#        self.texts = [f["question_" + language] for f in faq_list]
#        self.answers = [f["answer_" + language] for f in faq_list]
#        self.ids = [f["id"] for f in faq_list]
#        self._build_index()
#
#    def _build_index(self):
#        embeddings = self.model.encode(self.texts, convert_to_numpy=True)
#        faiss.normalize_L2(embeddings)
#        self.index = faiss.IndexFlatIP(embeddings.shape[1])
#        self.index.add(embeddings)
#
#    def retrieve(self, question, top_k=1):
#        query_vec = self.model.encode([question], convert_to_numpy=True)
#        faiss.normalize_L2(query_vec)
#        scores, indices = self.index.search(query_vec, top_k)
#        results = []
#        for idx in indices[0]:
#            results.append({
#                "id": self.ids[idx],
#                "question": self.texts[idx],
#                "answer": self.answers[idx],
#                "score": float(scores[0][np.where(indices[0]==idx)[0][0]])
#            })
#        return results
